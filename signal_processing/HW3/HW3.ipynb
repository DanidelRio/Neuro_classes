{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a05db40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import scipy.io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1115603f",
   "metadata": {},
   "source": [
    "Instructions: Each element in the array contains data on one trial. Time stamps for each spike in trial i and neuron j are given in r(i).unit(j).spikeTimes (in ms relative to trial start). Other relevant members of the structure for this homework assignment are: r(i).timeTouchHeld (the time the reach target appears and movement planning nominally begins), r(i).timeGoCue (the time the animal is cued to move and planning nominally ends), r(i).timeTargetAcquire (the time movement ends)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a088877",
   "metadata": {},
   "outputs": [],
   "source": [
    "spikeTimes = np.load('spikeTimes.npy', allow_pickle=True)\n",
    "timeGoCue = np.load('timeGoCue.npy', allow_pickle=True)\n",
    "timeTargetAcquire = np.load('timeTargetAcquire.npy', allow_pickle=True)\n",
    "timeTouchHeld = np.load('timeTouchHeld.npy', allow_pickle=True)\n",
    "cfr = np.load('cfr.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c10cef80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480\n",
      "1485\n",
      "2005\n",
      "[549.51354167 595.64166667 669.74583333]\n"
     ]
    }
   ],
   "source": [
    "print(timeTouchHeld[0])\n",
    "print(timeGoCue[0])\n",
    "print(timeTargetAcquire[0])\n",
    "print(spikeTimes[0][0]) # Claro, porque la neurona 0 disparo 3 veces, en la prueba 0.\n",
    "# Y los tiempos que dice ahi es cuando ocurrio eso, que fue entre timeTouchHeld y timeGoCue\n",
    "# print(spikeTimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bda0fc27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  8,  1, ...,  7,  8, 13],\n",
       "       [ 1,  6,  0, ...,  4,  9, 12],\n",
       "       [ 1,  3,  2, ...,  9, 11, 17],\n",
       "       ...,\n",
       "       [ 0,  7,  0, ...,  7,  3,  5],\n",
       "       [ 0,  4,  0, ...,  8,  4, 11],\n",
       "       [ 2,  9,  0, ..., 12,  3,  8]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example code for finding the number of spikes in the plan window\n",
    "\n",
    "planSpikes = []\n",
    "\n",
    "for trialIdx, trialSpikes in enumerate(spikeTimes): #what does st mean?\n",
    "    planSpikes.append([np.sum((st > timeTouchHeld[trialIdx]) & (st < timeGoCue[trialIdx])) for st in trialSpikes])\n",
    "\n",
    "planSpikes = np.array(planSpikes) # will be 1127 x 190 (number of trials by number of neurons)\n",
    "planSpikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c48ff79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  8,  3, ...,  7,  5, 19],\n",
       "       [ 0,  5,  1, ...,  1, 20, 14],\n",
       "       [ 0,  8,  1, ...,  2, 10, 21],\n",
       "       ...,\n",
       "       [ 0,  5,  0, ...,  3, 13, 19],\n",
       "       [ 0,  7,  0, ...,  1, 13,  3],\n",
       "       [ 0,  5,  2, ...,  3,  7, 10]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modified example code for finding the number of spikes in the movement window\n",
    "\n",
    "movementSpikes = []\n",
    "\n",
    "for trialIdx, trialSpikes in enumerate(spikeTimes): #what does st mean?\n",
    "     movementSpikes.append([np.sum((st > timeGoCue[trialIdx]) & (st < timeTargetAcquire[trialIdx])) for st in trialSpikes])\n",
    "\n",
    "movementSpikes = np.array(movementSpikes) # will be 1127 x 190 (number of trials by number of neurons)\n",
    "movementSpikes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935d139e",
   "metadata": {},
   "source": [
    "### Obtaining the rates (lambdas) for each neuron in each trial in the plan, movement and trial-movement window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7d4d738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00298507, 0.0079602 , 0.00099502, ..., 0.00696517, 0.0079602 ,\n",
       "        0.01293532],\n",
       "       [0.00099502, 0.00597015, 0.        , ..., 0.0039801 , 0.00895522,\n",
       "        0.0119403 ],\n",
       "       [0.00099502, 0.00298507, 0.00199005, ..., 0.00895522, 0.01094527,\n",
       "        0.01691542],\n",
       "       ...,\n",
       "       [0.        , 0.00927152, 0.        , ..., 0.00927152, 0.00397351,\n",
       "        0.00662252],\n",
       "       [0.        , 0.0039801 , 0.        , ..., 0.0079602 , 0.0039801 ,\n",
       "        0.01094527],\n",
       "       [0.00199005, 0.00895522, 0.        , ..., 0.0119403 , 0.00298507,\n",
       "        0.0079602 ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials = 1127   # 1127 trials\n",
    "neurons = 190  # 190 neurons\n",
    "\n",
    "lambda_planSpikes = np.zeros((1127,190))\n",
    "lambda_movementSpikes = np.zeros((1127,190))\n",
    "lambda_plan_move_Spikes = np.zeros((1127,190))\n",
    "\n",
    "for trial_i in range(trials):\n",
    "    for neuron_i in range(neurons):\n",
    "        lambda_planSpikes[trial_i][neuron_i] = planSpikes[trial_i][neuron_i]/(timeGoCue[trial_i]-timeTouchHeld[trial_i])\n",
    "        lambda_movementSpikes[trial_i][neuron_i] = movementSpikes[trial_i][neuron_i]/(timeTargetAcquire[trialIdx]-timeGoCue[trial_i])\n",
    "        \n",
    "        #Combined data\n",
    "        spikes = planSpikes[trial_i][neuron_i] + movementSpikes[trial_i][neuron_i]\n",
    "        time_window = (timeGoCue[trial_i]-timeTouchHeld[trial_i]) + (timeTargetAcquire[trialIdx]-timeGoCue[trial_i])\n",
    "        lambda_plan_move_Spikes[trial_i][neuron_i] = spikes/time_window\n",
    "        \n",
    "lambda_planSpikes        \n",
    "# lambda_movementSpikes\n",
    "# lambda_plan_move_Spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73c32fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "# The cfr has the objective of each trial.\n",
    "# Randomly choose 50 data sets for each direction, that is 400 sets in total.\n",
    "\n",
    "# Indices of each objective\n",
    "vec_1 = [i for i in range(len(cfr)) if cfr[i] == 1]\n",
    "vec_2 = [i for i in range(len(cfr)) if cfr[i] == 2]\n",
    "vec_3 = [i for i in range(len(cfr)) if cfr[i] == 3]\n",
    "vec_4 = [i for i in range(len(cfr)) if cfr[i] == 4]\n",
    "vec_5 = [i for i in range(len(cfr)) if cfr[i] == 5]\n",
    "vec_6 = [i for i in range(len(cfr)) if cfr[i] == 6]\n",
    "vec_7 = [i for i in range(len(cfr)) if cfr[i] == 7]\n",
    "vec_8 = [i for i in range(len(cfr)) if cfr[i] == 8]\n",
    "\n",
    "# Training indices for each objective\n",
    "training_1 = random.sample(vec_1, 50)\n",
    "training_2 = random.sample(vec_2, 50)\n",
    "training_3 = random.sample(vec_3, 50)\n",
    "training_4 = random.sample(vec_4, 50)\n",
    "training_5 = random.sample(vec_5, 50)\n",
    "training_6 = random.sample(vec_6, 50)\n",
    "training_7 = random.sample(vec_7, 50)\n",
    "training_8 = random.sample(vec_8, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fa06783",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "727\n"
     ]
    }
   ],
   "source": [
    "# Organizing the training and testing indices\n",
    "training_indices = np.column_stack((training_1, training_2, training_3, training_4,\n",
    "                                    training_5, training_6, training_7, training_8))\n",
    "training_indices = training_indices.reshape(400)\n",
    "training_indices = np.sort(training_indices)\n",
    "training_indices\n",
    "\n",
    "testing_indices = []\n",
    "\n",
    "for i in range(trials):\n",
    "    if i not in training_indices:\n",
    "        testing_indices.append(i)\n",
    "\n",
    "print(np.size(training_indices))\n",
    "print(np.size(testing_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "796d5327",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+000 1.77863633e-322 4.70844560e-321 ... 3.49157524e-006\n",
      "  1.23709927e-004 7.88771375e-003]\n",
      " [0.00000000e+000 1.97626258e-322 5.34579029e-321 ... 2.97737801e-006\n",
      "  1.48602682e-004 9.37972390e-003]\n",
      " [0.00000000e+000 1.43279037e-322 5.38531554e-321 ... 3.76517413e-006\n",
      "  2.20753188e-004 7.38413891e-003]\n",
      " ...\n",
      " [0.00000000e+000 2.27270197e-322 2.14424490e-321 ... 3.01174920e-006\n",
      "  2.31085631e-004 7.56970116e-003]\n",
      " [0.00000000e+000 2.27270197e-322 2.90016534e-321 ... 3.34734276e-006\n",
      "  1.19171032e-004 9.38433660e-003]\n",
      " [0.00000000e+000 2.27270197e-322 2.36657444e-321 ... 3.23136635e-006\n",
      "  1.40626668e-004 7.86030114e-003]]\n",
      "[[0.00000000e+000 6.27463370e-322 6.40803143e-321 ... 2.02312450e-006\n",
      "  5.13829186e-004 1.93740148e-002]\n",
      " [0.00000000e+000 6.42285340e-322 5.62740771e-321 ... 2.36637410e-006\n",
      "  4.13388172e-004 2.81086046e-002]\n",
      " [0.00000000e+000 7.06513874e-322 1.02172776e-320 ... 3.62924348e-006\n",
      "  8.97192119e-004 3.06128316e-002]\n",
      " ...\n",
      " [0.00000000e+000 6.47225996e-322 3.05332569e-321 ... 2.29007429e-006\n",
      "  4.18802387e-004 1.95409814e-002]\n",
      " [0.00000000e+000 4.34777768e-322 3.18178276e-321 ... 2.58313447e-006\n",
      "  3.05140087e-004 2.73244482e-002]\n",
      " [0.00000000e+000 4.89124989e-322 2.19365147e-321 ... 2.34389219e-006\n",
      "  3.45288225e-004 2.01621092e-002]]\n",
      "[[0.00000000e+000 3.40905296e-322 5.32108701e-321 ... 2.86264848e-006\n",
      "  2.70601897e-004 1.20789660e-002]\n",
      " [0.00000000e+000 3.50786609e-322 5.32108701e-321 ... 2.67459074e-006\n",
      "  2.39051743e-004 1.61682222e-002]\n",
      " [0.00000000e+000 2.86558075e-322 5.06911353e-321 ... 3.26577344e-006\n",
      "  3.41206961e-004 1.16205648e-002]\n",
      " ...\n",
      " [0.00000000e+000 3.70549234e-322 2.25293935e-321 ... 2.69576584e-006\n",
      "  2.88413092e-004 1.12119883e-002]\n",
      " [0.00000000e+000 3.06320700e-322 2.83593681e-321 ... 2.91940395e-006\n",
      "  1.88967329e-004 1.63032127e-002]\n",
      " [0.00000000e+000 3.26083326e-322 2.26282066e-321 ... 2.80380980e-006\n",
      "  2.19402405e-004 1.25724366e-002]]\n"
     ]
    }
   ],
   "source": [
    "# Obtaining the lambdas we will use for evaluating in the Poisson model\n",
    "# There are lambdas for planning, movement and plan_movement epochs.\n",
    "\n",
    "lambda_plan = np.zeros((8, 190))\n",
    "lambda_movement = np.zeros((8, 190))\n",
    "lambda_plan_move = np.zeros((8, 190))\n",
    "\n",
    "for neuron_i in range(190):\n",
    "    for i in training_1: #Cycle for training data in 1st direction\n",
    "        lambda_plan[0][neuron_i] += lambda_planSpikes[i][neuron_i] # Lambda for neuron i\n",
    "        lambda_movement[0][neuron_i] += lambda_movementSpikes[i][neuron_i] # Lambda for neuron i\n",
    "        lambda_plan_move[0][neuron_i] += lambda_plan_move_Spikes[i][neuron_i] # Lambda for neuron i\n",
    "    \n",
    "    for i in training_2: #Cycle for training data in 2nd direction\n",
    "        lambda_plan[1][neuron_i] += lambda_planSpikes[i][neuron_i] # Lambda for neuron i\n",
    "        lambda_movement[1][neuron_i] += lambda_movementSpikes[i][neuron_i] # Lambda for neuron i\n",
    "        lambda_plan_move[1][neuron_i] += lambda_plan_move_Spikes[i][neuron_i] # Lambda for neuron i\n",
    "\n",
    "    for i in training_3: #Cycle for training data in 3rd direction\n",
    "        lambda_plan[2][neuron_i] += lambda_planSpikes[i][neuron_i] # Lambda for neuron i\n",
    "        lambda_movement[2][neuron_i] += lambda_movementSpikes[i][neuron_i] # Lambda for neuron i\n",
    "        lambda_plan_move[2][neuron_i] += lambda_plan_move_Spikes[i][neuron_i] # Lambda for neuron i\n",
    "\n",
    "    for i in training_4: #Cycle for training data in 4th direction\n",
    "        lambda_plan[3][neuron_i] += lambda_planSpikes[i][neuron_i] # Lambda for neuron i\n",
    "        lambda_movement[3][neuron_i] += lambda_movementSpikes[i][neuron_i] # Lambda for neuron i\n",
    "        lambda_plan_move[3][neuron_i] += lambda_plan_move_Spikes[i][neuron_i] # Lambda for neuron i\n",
    "\n",
    "    for i in training_5: #Cycle for training data in 5th direction\n",
    "        lambda_plan[4][neuron_i] += lambda_planSpikes[i][neuron_i] # Lambda for neuron i\n",
    "        lambda_movement[4][neuron_i] += lambda_movementSpikes[i][neuron_i] # Lambda for neuron i\n",
    "        lambda_plan_move[4][neuron_i] += lambda_plan_move_Spikes[i][neuron_i] # Lambda for neuron i\n",
    "\n",
    "    for i in training_6: #Cycle for training data in 6th direction\n",
    "        lambda_plan[5][neuron_i] += lambda_planSpikes[i][neuron_i] # Lambda for neuron i\n",
    "        lambda_movement[5][neuron_i] += lambda_movementSpikes[i][neuron_i] # Lambda for neuron i\n",
    "        lambda_plan_move[5][neuron_i] += lambda_plan_move_Spikes[i][neuron_i] # Lambda for neuron i\n",
    "\n",
    "    for i in training_7: #Cycle for training data in 7th direction\n",
    "        lambda_plan[6][neuron_i] += lambda_planSpikes[i][neuron_i] # Lambda for neuron i\n",
    "        lambda_movement[6][neuron_i] += lambda_movementSpikes[i][neuron_i] # Lambda for neuron i\n",
    "        lambda_plan_move[6][neuron_i] += lambda_plan_move_Spikes[i][neuron_i] # Lambda for neuron i\n",
    "\n",
    "    for i in training_8: #Cycle for training data in 8th direction\n",
    "        lambda_plan[7][neuron_i] += lambda_planSpikes[i][neuron_i] # Lambda for neuron i\n",
    "        lambda_movement[7][neuron_i] += lambda_movementSpikes[i][neuron_i] # Lambda for neuron i\n",
    "        lambda_plan_move[7][neuron_i] += lambda_plan_move_Spikes[i][neuron_i] # Lambda for neuron i\n",
    "\n",
    "    # You could continue making one lambda array for each direction for neuron i\n",
    "    \n",
    "    for i in range(8):\n",
    "        lambda_plan[i] = lambda_plan[i]/50\n",
    "        lambda_movement[i] = lambda_movement[i]/50\n",
    "        lambda_plan_move[i] = lambda_plan_move[i]/50\n",
    "        \n",
    "print(lambda_plan) #8*190 = 1520\n",
    "print(lambda_movement) #8*190\n",
    "print(lambda_plan_move) # 8*190"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e8a26a",
   "metadata": {},
   "source": [
    "At least until here, it is running okey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2432bfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Likelihood equation\n",
    "def Poisson(x_d, lambda_d): #This formula is only for the testing data\n",
    "\n",
    "    if lambda_d < 1e-100: # Very small lambdas return a value that goes to infty.\n",
    "        log_term = -230*x_d\n",
    "    else:\n",
    "        log_term = x_d*np.log(lambda_d)\n",
    "        \n",
    "#     if x_d >20: # For more than 20 spikes, the log(spikes!) comes with an error message\n",
    "#         # AttributeError: 'int' object has no attribute 'log'\n",
    "#         # np.log(math.factorial(20)) # For numbers greater than 20, there comes this error message\n",
    "#         factorial = np.log(np.double(np.math.factorial(x_d)))\n",
    "#     else:\n",
    "#         factorial = np.log(math.factorial(x_d))\n",
    "        \n",
    "    return -lambda_d + log_term # - factorial\n",
    "# Note the factorial term does not matter because it is the same term for each direction, so when you compare them,\n",
    "# it does not make a difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "431e9100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This sample code is for running ONE trial.\n",
    "# testing_i = testing_indices[2]\n",
    "# aux_plan = np.zeros(8)\n",
    "# aux_move = np.zeros(8)\n",
    "\n",
    "# for direction_i in range(8):\n",
    "#     for neuron_i in range(neurons):\n",
    "#         aux_plan[direction_i] += Poisson(planSpikes[testing_i][neuron_i], lambda_d[direction_i][neuron_i])\n",
    "#         aux_move[direction_i] += Poisson(movementSpikes[testing_i][neuron_i], lambda_movementSpikes[direction_i][neuron_i])\n",
    "        \n",
    "        \n",
    "# print(aux_plan)\n",
    "# print(np.argmax(aux_plan)+1)\n",
    "\n",
    "# print(\"For movement\")\n",
    "# print(aux_move)\n",
    "# print(np.argmax(aux_move)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b281a3e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6. 3. 6. 6. 6. 1. 3. 3. 1. 3. 6. 6. 7. 6. 3. 3. 3. 3. 7. 3. 1. 3. 6. 3.\n",
      " 3. 3. 3. 1. 1. 6. 1. 3. 3. 6. 6. 6. 3. 3. 1. 3. 6. 3. 3. 3. 1. 3. 1. 6.\n",
      " 6. 3. 6. 3. 3. 3. 6. 3. 1. 6. 3. 1. 3. 6. 3. 3. 3. 6. 3. 6. 3. 1. 3. 3.\n",
      " 3. 6. 6. 6. 3. 6. 3. 3. 6. 3. 1. 6. 6. 3. 3. 3. 3. 3. 3. 3. 3. 6. 3. 3.\n",
      " 6. 6. 3. 6. 3. 3. 3. 6. 3. 3. 3. 1. 3. 3. 3. 3. 6. 3. 6. 3. 3. 3. 6. 3.\n",
      " 3. 1. 6. 3. 3. 3. 3. 3. 6. 3. 3. 6. 3. 1. 3. 3. 6. 3. 6. 3. 6. 7. 6. 3.\n",
      " 1. 3. 3. 3. 3. 3. 3. 1. 6. 6. 3. 1. 3. 6. 3. 3. 1. 6. 3. 6. 3. 3. 3. 3.\n",
      " 3. 6. 6. 3. 1. 3. 1. 6. 3. 3. 3. 3. 6. 6. 3. 3. 1. 3. 3. 6. 3. 3. 3. 3.\n",
      " 1. 6. 7. 3. 6. 3. 3. 3. 3. 3. 3. 1. 1. 6. 1. 3. 6. 3. 3. 1. 1. 3. 3. 6.\n",
      " 6. 6. 3. 3. 3. 3. 3. 3. 1. 3. 1. 3. 6. 3. 6. 6. 3. 3. 3. 3. 6. 6. 3. 6.\n",
      " 3. 7. 3. 3. 3. 3. 6. 3. 6. 3. 6. 3. 3. 3. 3. 6. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 6. 6. 3. 3. 6. 1. 1. 3. 1. 3. 6. 6. 3. 1. 3. 6. 3. 3. 3. 3. 3. 1. 6. 1.\n",
      " 3. 1. 1. 6. 6. 6. 3. 1. 3. 3. 6. 3. 6. 6. 3. 3. 3. 3. 3. 3. 3. 6. 6. 6.\n",
      " 3. 3. 3. 1. 3. 6. 3. 3. 3. 3. 1. 1. 3. 6. 3. 6. 3. 1. 6. 3. 1. 6. 3. 3.\n",
      " 3. 6. 3. 3. 3. 3. 3. 3. 6. 3. 3. 6. 3. 3. 3. 3. 6. 3. 1. 6. 3. 1. 3. 3.\n",
      " 3. 7. 3. 6. 6. 1. 6. 6. 3. 3. 1. 1. 3. 6. 3. 3. 3. 6. 3. 6. 3. 3. 6. 3.\n",
      " 3. 6. 6. 3. 6. 3. 6. 3. 3. 6. 3. 3. 1. 3. 3. 6. 3. 3. 1. 6. 6. 6. 1. 3.\n",
      " 3. 6. 1. 3. 6. 6. 6. 3. 1. 3. 6. 6. 3. 3. 1. 6. 1. 3. 5. 3. 3. 3. 3. 3.\n",
      " 3. 6. 3. 3. 6. 3. 3. 3. 3. 3. 3. 6. 6. 3. 3. 3. 3. 6. 3. 1. 6. 6. 1. 3.\n",
      " 6. 1. 3. 3. 1. 3. 3. 6. 1. 7. 3. 3. 1. 1. 3. 6. 3. 6. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 6. 1. 1. 1. 3. 3. 6. 3. 3. 3. 6. 1. 6. 3. 3. 3. 3. 3. 6. 3. 3. 6.\n",
      " 3. 3. 3. 6. 3. 6. 1. 6. 6. 3. 3. 3. 6. 6. 3. 6. 3. 3. 3. 7. 1. 6. 3. 3.\n",
      " 6. 3. 3. 1. 3. 3. 3. 6. 1. 3. 7. 3. 3. 3. 3. 6. 3. 3. 1. 6. 3. 3. 3. 3.\n",
      " 6. 3. 6. 3. 6. 3. 6. 1. 3. 1. 6. 3. 1. 3. 6. 6. 3. 3. 3. 3. 6. 6. 3. 3.\n",
      " 3. 3. 6. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 6. 3. 6. 3. 3. 6. 3. 3. 6. 3.\n",
      " 3. 6. 3. 3. 3. 3. 3. 7. 3. 1. 3. 3. 6. 1. 3. 6. 3. 3. 3. 6. 6. 7. 3. 3.\n",
      " 1. 3. 3. 3. 3. 3. 6. 3. 3. 3. 3. 3. 3. 6. 3. 3. 3. 3. 3. 3. 6. 1. 3. 3.\n",
      " 3. 6. 3. 3. 3. 6. 6. 3. 3. 3. 3. 3. 3. 6. 3. 3. 3. 3. 6. 6. 3. 6. 3. 3.\n",
      " 6. 6. 3. 3. 3. 3. 6. 3. 6. 1. 3. 3. 6. 3. 3. 1. 6. 1. 3. 3. 6. 3. 3. 3.\n",
      " 3. 6. 3. 6. 1. 3. 3. 3. 6. 3. 3. 3. 3. 6. 3. 3. 3. 6. 1. 6. 3. 3. 3. 6.\n",
      " 3. 6. 3. 3. 6. 3. 3.]\n",
      "[3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 4. 3.\n",
      " 3. 3. 3. 4. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 4. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3.]\n",
      "[4. 4. 4. 4. 4. 4. 3. 3. 4. 3. 4. 3. 4. 4. 1. 1. 4. 4. 4. 3. 1. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 3. 4. 4. 4. 1. 4. 4. 3. 4. 1. 4. 3. 4. 3. 4. 4.\n",
      " 4. 4. 4. 4. 4. 3. 4. 3. 4. 3. 4. 4. 4. 4. 3. 3. 4. 4. 4. 3. 3. 4. 4. 1.\n",
      " 4. 4. 3. 4. 4. 4. 4. 3. 4. 4. 3. 4. 4. 3. 4. 4. 3. 3. 4. 4. 4. 4. 3. 4.\n",
      " 1. 4. 4. 3. 4. 1. 4. 4. 3. 4. 4. 4. 3. 4. 4. 4. 4. 4. 4. 1. 3. 4. 4. 3.\n",
      " 4. 4. 1. 3. 3. 4. 4. 4. 4. 4. 3. 3. 4. 1. 3. 1. 3. 4. 3. 4. 4. 4. 4. 4.\n",
      " 1. 3. 3. 3. 4. 4. 4. 3. 3. 4. 4. 4. 3. 3. 1. 1. 4. 1. 4. 3. 4. 3. 4. 3.\n",
      " 4. 4. 4. 1. 4. 3. 4. 3. 4. 3. 4. 3. 4. 4. 4. 4. 4. 4. 4. 4. 4. 3. 3. 4.\n",
      " 4. 4. 4. 1. 4. 3. 4. 4. 4. 1. 4. 4. 3. 4. 4. 3. 4. 4. 3. 4. 4. 1. 3. 3.\n",
      " 4. 4. 3. 4. 4. 4. 4. 4. 4. 3. 4. 4. 4. 4. 4. 3. 4. 3. 3. 4. 4. 4. 4. 3.\n",
      " 1. 4. 4. 4. 1. 3. 4. 4. 3. 4. 4. 4. 4. 4. 1. 4. 4. 1. 3. 4. 3. 3. 4. 4.\n",
      " 4. 3. 4. 1. 4. 4. 4. 4. 4. 3. 4. 4. 4. 4. 4. 3. 1. 4. 4. 4. 3. 4. 4. 1.\n",
      " 3. 4. 4. 3. 1. 3. 3. 3. 3. 4. 4. 3. 4. 4. 3. 3. 4. 3. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 1. 3. 4. 3. 4. 4. 4. 4. 4. 3. 4. 3. 4. 4. 4. 4. 3. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 1. 4. 1. 3. 3. 4. 4. 4. 1. 4. 4. 4. 4. 4. 3. 3. 4. 4. 4. 3.\n",
      " 4. 4. 4. 4. 4. 4. 3. 4. 4. 1. 4. 4. 1. 3. 4. 4. 4. 4. 3. 4. 3. 4. 4. 4.\n",
      " 3. 4. 4. 4. 4. 4. 4. 4. 3. 4. 3. 4. 4. 4. 1. 4. 1. 3. 4. 4. 3. 4. 4. 4.\n",
      " 3. 3. 4. 1. 4. 4. 3. 4. 4. 4. 3. 4. 4. 1. 4. 4. 4. 3. 4. 4. 4. 4. 3. 4.\n",
      " 3. 3. 4. 4. 1. 3. 4. 4. 1. 3. 4. 4. 4. 4. 3. 3. 4. 4. 4. 1. 3. 1. 4. 4.\n",
      " 4. 4. 1. 4. 4. 4. 3. 4. 4. 4. 3. 4. 4. 4. 4. 4. 4. 4. 3. 3. 4. 4. 1. 3.\n",
      " 4. 4. 4. 4. 4. 1. 4. 4. 4. 3. 4. 4. 4. 4. 3. 4. 4. 3. 4. 4. 3. 3. 3. 4.\n",
      " 4. 1. 4. 4. 1. 4. 4. 4. 4. 4. 4. 3. 4. 4. 3. 1. 4. 4. 3. 4. 1. 1. 4. 4.\n",
      " 1. 3. 4. 4. 1. 3. 3. 4. 4. 1. 4. 4. 4. 1. 4. 4. 4. 3. 4. 4. 4. 4. 4. 4.\n",
      " 1. 3. 4. 4. 4. 4. 4. 1. 4. 4. 4. 1. 3. 3. 3. 3. 4. 4. 3. 4. 3. 4. 3. 3.\n",
      " 4. 4. 3. 4. 4. 4. 4. 4. 4. 4. 3. 4. 4. 4. 4. 1. 1. 4. 1. 3. 1. 4. 1. 3.\n",
      " 3. 3. 3. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 3. 4. 1. 3. 4. 4. 4. 1. 4.\n",
      " 4. 4. 3. 4. 4. 4. 3. 3. 4. 4. 4. 4. 1. 3. 4. 1. 4. 3. 1. 4. 4. 3. 4. 4.\n",
      " 4. 4. 4. 1. 4. 1. 4. 3. 4. 3. 4. 4. 4. 4. 4. 4. 3. 4. 4. 4. 4. 4. 4. 1.\n",
      " 3. 3. 4. 1. 4. 4. 4. 4. 4. 1. 3. 4. 4. 4. 4. 4. 4. 1. 4. 3. 1. 4. 4. 4.\n",
      " 4. 4. 3. 4. 4. 4. 3. 4. 3. 4. 3. 3. 3. 4. 4. 4. 4. 4. 4. 4. 3. 3. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 3.]\n"
     ]
    }
   ],
   "source": [
    "# Poisson values for the planning and movement data\n",
    "direction_values_plan = np.zeros(len(testing_indices))\n",
    "direction_values_move = np.zeros(len(testing_indices))\n",
    "direction_values_plan_move = np.zeros(len(testing_indices))\n",
    "i = 0\n",
    "\n",
    "for testing_i in testing_indices:\n",
    "    aux_plan = np.zeros(8)\n",
    "    aux_move = np.zeros(8)\n",
    "    aux_plan_move = np.zeros(8)\n",
    "    \n",
    "    for direction_i in range(8):\n",
    "        for neuron_i in range(neurons):\n",
    "\n",
    "            aux_plan[direction_i] += Poisson(lambda_planSpikes[testing_i][neuron_i], lambda_plan[direction_i][neuron_i])\n",
    "            aux_move[direction_i] += Poisson(lambda_movementSpikes[testing_i][neuron_i], lambda_movement[direction_i][neuron_i])\n",
    "            aux_plan_move[direction_i] += Poisson(lambda_plan_move_Spikes[testing_i][neuron_i], lambda_plan_move[direction_i][neuron_i])\n",
    "              \n",
    "    direction_values_plan[i] = np.argmax(aux_plan)+1\n",
    "    direction_values_move[i] = np.argmax(aux_move)+1\n",
    "    direction_values_plan_move[i] = np.argmax(aux_plan_move)+1\n",
    "    \n",
    "    i+=1 # This is only an index for the testing_indices\n",
    "    \n",
    "print(direction_values_plan)\n",
    "print(direction_values_move)\n",
    "print(direction_values_plan_move)\n",
    "# Notice you did a change here. The last 3 arrays you called cannot be called with the same index as the original values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b93e7fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct trials in planning:  0.2764786795048143\n",
      "Correct trials in movement:  0.1279229711141678\n",
      "Correct trials in planning and movement:  0.3314993122420908\n",
      "Chance:  0.125\n"
     ]
    }
   ],
   "source": [
    "# Correctness of trials\n",
    "i = 0\n",
    "correct_trials_plan = 0\n",
    "correct_trials_move = 0\n",
    "correct_trials_plan_move = 0\n",
    "\n",
    "# Yes, you must call them with different indices because they have different sizes.\n",
    "# But you did the correct mapping.\n",
    "for testing_i in testing_indices:\n",
    "    \n",
    "    if cfr[testing_i] == direction_values_plan[i]:\n",
    "        correct_trials_plan += 1\n",
    "    \n",
    "    if cfr[testing_i] == direction_values_move[i]:\n",
    "        correct_trials_move += 1\n",
    "    \n",
    "    if cfr[testing_i] == direction_values_plan_move[i]:\n",
    "        correct_trials_plan_move += 1\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "print(\"Correct trials in planning: \", correct_trials_plan/len(testing_indices))\n",
    "print(\"Correct trials in movement: \", correct_trials_move/len(testing_indices))\n",
    "print(\"Correct trials in planning and movement: \", correct_trials_plan_move/len(testing_indices))\n",
    "print(\"Chance: \",1/8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5117bc2d",
   "metadata": {},
   "source": [
    "# BEWARE if you are getting best decoding numbers below 90% you probably have not properly calculated rates or properly applied the rates to the right duration windows for each trial. Remember that a Poisson process is defined by λ∗T!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f8f874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f598da78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c7682e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d022a276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the training data to estimate the parameters of a target- direction-dependent vector Poisson process\n",
    "# calculate a Poisson model for each neuron and class - the rate for a class will be a vector the size of the number of neurons.\n",
    "\n",
    "# How do we estimate a Poisson model with the given data?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37de9dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de147ccb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58a6783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1661e084",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4652592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f78987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a256f20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c39624",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
